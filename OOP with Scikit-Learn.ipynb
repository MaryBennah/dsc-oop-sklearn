{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOP with Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "As you learn more about machine learning algorithms, there are typically two components. First, the conceptual underlying logic of the algorithm -- how it works to process inputs and generate outputs. Second, the scikit-learn implementation of the algorithm -- how to use it in practice.\n",
    "\n",
    "Before diving into specific examples of various scikit-learn models, it is helpful to understand the general structure they follow. Specifically, we'll go over some key classes, methods, and attributes common to scikit-learn.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "In this lesson you will:\n",
    "\n",
    "* Recall the distinction between mutable and immutable types\n",
    "* Define the four main inherited object types in scikit-learn\n",
    "* Instantiate scikit-learn transformers and models\n",
    "* Invoke scikit-learn methods\n",
    "* Access scikit-learn attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutable and Immutable Data Types\n",
    "\n",
    "In base Python, the built-in types are either mutable or immutable.\n",
    "\n",
    "***Mutable*** data types are data types that can be modified after they are initialized. For example, a list is a mutable data type in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list = [1, 2, 3]\n",
    "my_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way you can mutate a Python `list` is using the `append` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list.append(4)\n",
    "my_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is in contrast to ***immutable*** data types, which can't be modified after they are initialized. For example, a string is an immutable data type in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_str = \"Hello!\"\n",
    "my_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call methods on strings, but it doesn't modify their value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_str.upper()\n",
    "my_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This same principle applies to custom classes beyond base Python, including the classes used by scikit-learn.\n",
    "\n",
    "**Most scikit-learn classes are** ***mutable***, which means that calling methods on them changes their internal data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn Classes\n",
    "\n",
    "Scikit-learn has four main classes to be aware of:\n",
    "\n",
    "* Estimator\n",
    "* Transformer\n",
    "* Predictor\n",
    "* Model\n",
    "\n",
    "They are defined based on which methods they possess. The classes are **not mutually exclusive**. \n",
    "\n",
    "### Estimator\n",
    "\n",
    "![estimator table, where StandardScaler, PCA, KMeans, and LinearRegression are all checked off](https://curriculum-content.s3.amazonaws.com/data-science/images/estimator.png)\n",
    "\n",
    "Almost all scikit-learn classes you will use will be some kind of estimator. It is the \"base object\" in scikit-learn.\n",
    "\n",
    "An estimator is defined by having a `fit` method. There are two typical forms for this method:\n",
    "\n",
    "```python\n",
    "estimator.fit(data)\n",
    "```\n",
    "\n",
    "and\n",
    "\n",
    "```python\n",
    "estimator.fit(X, y)\n",
    "```\n",
    "\n",
    "The first one is typically used in the context of a transformer or unsupervised learning predictor, while the second is used in the context of a supervised learning predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer\n",
    "\n",
    "![transformer table, where StandardScaler, PCA and KMeans are checked off](https://curriculum-content.s3.amazonaws.com/data-science/images/transformer.png)\n",
    "\n",
    "A transformer is an estimator that has a `transform` method:\n",
    "\n",
    "```python\n",
    "transformer.transform(data)\n",
    "```\n",
    "\n",
    "The `transform` method is called after the `fit` method and returns a modified form of the input data.\n",
    "\n",
    "An example of a transformer (that is not also a predictor or model) is:\n",
    "\n",
    "#### `StandardScaler`\n",
    "\n",
    "`StandardScaler` is used to standardize features by removing the mean and scaling to unit variance ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import class from scikit-learn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Instantiate the scaler (same step for all estimators, though specific args differ)\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the estimator is first instantiated, these are all of its attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'with_mean': True, 'with_std': True, 'copy': True}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note: the `__dict__` attribute starts with an underscore so it is not intended for \"public\" use and may not work consistently in the future. Look at the documentation page to see the list of public attributes.)\n",
    "\n",
    "The next step, like with any scikit-learn estimator, is to fit the scaler on the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data representing a single feature\n",
    "data = [[10], [20], [30], [40], [50]]\n",
    "\n",
    "# Fit the scaler (same step for all estimators, though specific args differ)\n",
    "scaler.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that `fit` has been called, because transformers are *mutable*, there are additional attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'with_mean': True,\n",
       " 'with_std': True,\n",
       " 'copy': True,\n",
       " 'n_features_in_': 1,\n",
       " 'n_samples_seen_': 5,\n",
       " 'mean_': array([30.]),\n",
       " 'var_': array([200.]),\n",
       " 'scale_': array([14.14213562])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The underscore (`_`) at the end of these new variables (e.g. `mean_`) is a scikit-learn convention, which means that these attributes are not available until the estimator has been fit.\n",
    "\n",
    "We can access these fitted attributes using the standard dot notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.mean_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the scaler is fit, we can use it to transform the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.41421356],\n",
       "       [-0.70710678],\n",
       "       [ 0.        ],\n",
       "       [ 0.70710678],\n",
       "       [ 1.41421356]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that even though we passed in a base Python list, the scaler returned a NumPy `ndarray`. Transformers always return this type of array regardless of whether you pass in a base Python data structure, a NumPy data structure, or a pandas data structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some additional examples of transformers (that aren't also predictors) are:\n",
    "\n",
    "* [`OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html): used to convert categorical features into one-hot encoded features\n",
    "* [`CountVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html): used to convert text data into a matrix of token counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictor\n",
    "\n",
    "![predictor table, where KMeans and LinearRegression are checked off](https://curriculum-content.s3.amazonaws.com/data-science/images/predictor.png)\n",
    "\n",
    "As you might have...*predicted*...a predictor is an estimator that has a `predict` method:\n",
    "\n",
    "```python\n",
    "predictor.predict(X)\n",
    "```\n",
    "\n",
    "The `predict` method is called after the `fit` method and can be part of a supervised or unsupervised learning model. It returns a list of predictions `y` associated with the input data `X`.\n",
    "\n",
    "An example of a predictor is:\n",
    "\n",
    "#### `LinearRegression`\n",
    "\n",
    "`LinearRegression` is a class that represents an ordinary least squares linear regression model ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-9f2ddae37ebd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Import class from scikit-learn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Instantiate the model (same step for all estimators, though specific args differ)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_bayes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBayesianRidge\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mARDRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m from ._least_angle import (Lars, LassoLars, lars_path, lars_path_gram, LarsCV,\n\u001b[0m\u001b[0;32m     12\u001b[0m                            LassoLarsCV, LassoLarsIC)\n\u001b[0;32m     13\u001b[0m from ._coordinate_descent import (Lasso, ElasticNet, LassoCV, ElasticNetCV,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_deprecate_positional_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m def lars_path(X, y, Xy=None, *, Gram=None, max_iter=500, alpha_min=0,\n\u001b[1;32m---> 34\u001b[1;33m               \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lar'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy_X\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m               \u001b[0mcopy_Gram\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m               return_n_iter=False, positive=False):\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m__former_attrs__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__former_attrs__\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[1;31m# Importing Tester requires importing all of UnitTest which is not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "# Import class from scikit-learn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Instantiate the model (same step for all estimators, though specific args differ)\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the estimator is first instantiated, these are all of its attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step, like with any scikit-learn estimator, is to fit the linear regression on the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data representing X (features) and y (target), where y = 10x + 5\n",
    "X = [[1], [2], [3], [4], [5]]\n",
    "y = [15, 25, 35, 45, 55]\n",
    "\n",
    "# Fit the linear regression (same step for all estimators, though specific args differ)\n",
    "lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this differs from the `fit` method in the `StandardScaler` (and most transformers) because it requires both `X` and `y`.\n",
    "\n",
    "Once again, there are additional attributes now that `fit` has been called, since `LinearRegression` is mutable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the fitted attributes using dot notation. For example, below we access the intercept and coefficient of the regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr.intercept_)\n",
    "print(lr.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this is a predictor and not a transformer, the next step is to use the `predict` method rather than the `transform` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some additional examples of predictors (that aren't also transformers) are:\n",
    "\n",
    "* [`LogisticRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html): a classifier that uses the logistic regression algorithm\n",
    "* [`KNeighborsRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html): a regressor that uses the k-nearest neighbors algorithm\n",
    "* [`DecisionTreeClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html): a classifier that uses the decision tree algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "![model table, where PCA, KMeans, and LinearRegression are checked off](https://curriculum-content.s3.amazonaws.com/data-science/images/model.png)\n",
    "\n",
    "A model is an estimator that has a `score` method. There are two typical forms for this method:\n",
    "\n",
    "```python\n",
    "model.score(X, y)\n",
    "```\n",
    "\n",
    "and\n",
    "\n",
    "```python\n",
    "model.score(X)\n",
    "```\n",
    "\n",
    "For example, using the linear regression model from above, we can score the model using r-squared:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of a model that produces a score with just `X` would be `PCA` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import class from scikit-learn\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Instantiate the model (same step for all estimators, though specific args differ)\n",
    "pca = PCA(n_components=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data representing two features\n",
    "X = [[1, 11], [2, 12], [3, 14], [4, 16], [5, 18]]\n",
    "\n",
    "# Fit the PCA (same step for all estimators, though specific args differ)\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.score(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand what a given score means, look at the documentation for the model (e.g. [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html?highlight=score#sklearn.linear_model.LinearRegression.score) for `LinearRegression` or [here](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html?highlight=score#sklearn.decomposition.PCA.score) for `PCA`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlapping Classes\n",
    "\n",
    "As stated previously, these scikit-learn classes are not mutually exclusive.\n",
    "\n",
    "`StandardScaler` is an **estimator** and a **transformer** but not a predictor or a model.\n",
    "\n",
    "`LinearRegression` is an **estimator**, a **predictor**, and a **model** but not a transformer.\n",
    "\n",
    "`KMeans` is an **estimator**, a **transformer**, a **predictor**, and a **model**.\n",
    "\n",
    "`PCA` is an **estimator**, a **transformer**, and a **model** but not a predictor.\n",
    "\n",
    "(Don't worry if you're not sure what all of these classes are used for. We'll get there eventually!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "\n",
    "**You do not need to memorize** these labels for every scikit-learn class you encounter. You can always figure out what a class can do by looking at its documentation:\n",
    "\n",
    "* If it has a `fit` method, it's an estimator\n",
    "* If it has a `transform` method, it's a transformer\n",
    "* If it has a `predict` method, it's a predictor\n",
    "* If it has a `score` method, it's a model\n",
    "\n",
    "Recognizing these terms can help you navigate the official documentation as well as third-party resources, which might refer to these classes and their instances with various labels interchangeably, since multiple labels often apply.\n",
    "\n",
    "Also, keep in mind that estimators are mutable and store important information during the `fit` step, which means that you always need to call the `fit` method before you can call the `transform`, `predict`, or `score` methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lesson, you learned about the four main classes in scikit-learn: estimators, transformers, predictors, and models. You saw how the attributes of the estimators changed when the `fit` method was called, as well as how to use other methods such as `transform`, `predict`, and `score`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
